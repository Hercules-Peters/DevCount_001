{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hercules-Peters/DevCount_001/blob/main/Image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJTHs1wDHx3n"
      },
      "source": [
        "**Importing modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdVj5p8fs_jV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0hPdizmH7G8"
      },
      "source": [
        "**Loading CIFAR-10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm5pCArotKO0",
        "outputId": "dc51f40c-2cfc-4dc5-a1a2-7f89d607802d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alRbk0gpIHfn"
      },
      "source": [
        "**Normalizing pixel values to range [0, 1]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lgq8l0MMtR9c"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JtymJETKecz"
      },
      "source": [
        "**Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQXW80zYtWT0"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lpQZrNOKVEI"
      },
      "source": [
        "**Defining the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v12xNDE3tYsj"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2), padding='same'),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNuVVIgEJ8wB"
      },
      "source": [
        "**Compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_whCusR6tlSj"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml9ByFPNJ2rg"
      },
      "source": [
        "**Training the model with data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR6lbixOtnyK",
        "outputId": "9e88d91a-3c98-4cb9-c76a-ce8e91c94d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1562/1562 [==============================] - 220s 139ms/step - loss: 1.8495 - accuracy: 0.0951 - val_loss: 1.6356 - val_accuracy: 0.0564\n",
            "Epoch 2/15\n",
            "1562/1562 [==============================] - 214s 137ms/step - loss: 1.3478 - accuracy: 0.0983 - val_loss: 1.2595 - val_accuracy: 0.1425\n",
            "Epoch 3/15\n",
            "1562/1562 [==============================] - 216s 138ms/step - loss: 1.1672 - accuracy: 0.0999 - val_loss: 1.1682 - val_accuracy: 0.0758\n",
            "Epoch 4/15\n",
            "1562/1562 [==============================] - 240s 154ms/step - loss: 1.0566 - accuracy: 0.1019 - val_loss: 0.9287 - val_accuracy: 0.0991\n",
            "Epoch 5/15\n",
            "1562/1562 [==============================] - 221s 141ms/step - loss: 0.9994 - accuracy: 0.1003 - val_loss: 0.9950 - val_accuracy: 0.1199\n",
            "Epoch 6/15\n",
            "1562/1562 [==============================] - 217s 139ms/step - loss: 0.9442 - accuracy: 0.1018 - val_loss: 0.9020 - val_accuracy: 0.0783\n",
            "Epoch 7/15\n",
            "1562/1562 [==============================] - 215s 137ms/step - loss: 0.8989 - accuracy: 0.1010 - val_loss: 0.8312 - val_accuracy: 0.1016\n",
            "Epoch 8/15\n",
            "1562/1562 [==============================] - 216s 138ms/step - loss: 0.8689 - accuracy: 0.1022 - val_loss: 0.7282 - val_accuracy: 0.1022\n",
            "Epoch 9/15\n",
            "1562/1562 [==============================] - 219s 140ms/step - loss: 0.8436 - accuracy: 0.1026 - val_loss: 0.8199 - val_accuracy: 0.1102\n",
            "Epoch 10/15\n",
            "1562/1562 [==============================] - 220s 141ms/step - loss: 0.8252 - accuracy: 0.1018 - val_loss: 0.8364 - val_accuracy: 0.0880\n",
            "Epoch 11/15\n",
            "1562/1562 [==============================] - 218s 139ms/step - loss: 0.8090 - accuracy: 0.1016 - val_loss: 0.6432 - val_accuracy: 0.0980\n",
            "Epoch 12/15\n",
            "1562/1562 [==============================] - 218s 139ms/step - loss: 0.7895 - accuracy: 0.1010 - val_loss: 0.7401 - val_accuracy: 0.0895\n",
            "Epoch 13/15\n",
            "1562/1562 [==============================] - 218s 140ms/step - loss: 0.7755 - accuracy: 0.1015 - val_loss: 0.6737 - val_accuracy: 0.1092\n",
            "Epoch 14/15\n",
            "1562/1562 [==============================] - 231s 148ms/step - loss: 0.7570 - accuracy: 0.1020 - val_loss: 0.7196 - val_accuracy: 0.0955\n",
            "Epoch 15/15\n",
            "1562/1562 [==============================] - 220s 140ms/step - loss: 0.7475 - accuracy: 0.1014 - val_loss: 0.6544 - val_accuracy: 0.1064\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) / 32, epochs=15,\n",
        "                    validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM8p2Lzw_8Na",
        "outputId": "af1f0f06-9465-4d27-a001-3b36dacac79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 30, 30, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 28, 28, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 12, 12, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 10, 10, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 3, 3, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 1, 1, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 325418 (1.24 MB)\n",
            "Trainable params: 324010 (1.24 MB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3bIgD5jIo3Z"
      },
      "source": [
        "**Evaluating the model on test data**\n",
        "\n",
        "1. Since, we used 30 epochs the model might not be very accurate. But we can increase the number of epochs to have better outcomes however, it will take longer time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuli44Sdtwfr",
        "outputId": "3054aa4d-b7a9-40eb-ba27-886ff4c55047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 9s - loss: 0.6544 - accuracy: 0.1064 - 9s/epoch - 29ms/step\n",
            "Test accuracy: 0.10639999806880951\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Test accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUa257KFIXjH"
      },
      "source": [
        "**Saving our model for reusability**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vEjmoAnt6YU",
        "outputId": "20b95097-1f6d-49a7-fb91-a1071b571163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"cifar10_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHcLkcC9SCgM"
      },
      "source": [
        "**for uploading files for local storage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "SRJwCrYF7n_8",
        "outputId": "de15e7d7-e30d-42cd-a274-24b38b908f6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d459595c-c015-418b-a450-1b89dcc8cb0e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d459595c-c015-418b-a450-1b89dcc8cb0e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cow1.jpg to cow1.jpg\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "file = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn-K69nAMhfr"
      },
      "source": [
        "**Using our model to make predictions**\n",
        "\n",
        "1. Resize to match input shape of the model\n",
        "2. Normalize pixel values to [0, 1]\n",
        "3. Add batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "KlLtnBllyi0Y",
        "outputId": "1b9c22d2-ce6c-4f9e-bbba-fa2a0ba2d092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def predict_image(image_path):\n",
        "    class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((32, 32))\n",
        "    image_array = np.array(image) / 255.0\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    predicted_logits = model.predict(image_array)\n",
        "    predicted_class_index = np.argmax(predicted_logits)\n",
        "    predicted_class = class_names[predicted_class_index]\n",
        "\n",
        "    # Displaying the image\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Predicted class: \" + predicted_class)\n",
        "    plt.show()\n",
        "\n",
        "# Making predictions on a new image\n",
        "new_image_path = \"/content/horse2.jpg\"\n",
        "predict_image(new_image_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5N18Nv1OcMhCvXcPuhCdU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}